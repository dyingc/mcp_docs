# Providers | liteLLM

## [🗃️ OpenAI3 items](/docs/providers/openai)## [📄️ OpenAI (Text Completion)LiteLLM supports OpenAI text completion models](/docs/providers/text_completion_openai)## [📄️ OpenAI-Compatible EndpointsSelecting openai as the provider routes your request to an OpenAI-compatible endpoint using the upstream](/docs/providers/openai_compatible)## [🗃️ Azure OpenAI3 items](/docs/providers/azure/)## [📄️ Azure AI StudioLiteLLM supports all models on Azure AI Studio](/docs/providers/azure_ai)## [📄️ AI/ML APIGetting started with the AI/ML API is simple. Follow these steps to set up your integration:](/docs/providers/aiml)## [🗃️ Vertex AI2 items](/docs/providers/vertex)## [🗃️ Google AI Studio3 items](/docs/providers/gemini)## [📄️ AnthropicLiteLLM supports all anthropic models.](/docs/providers/anthropic)## [📄️ AWS SagemakerLiteLLM supports All Sagemaker Huggingface Jumpstart Models](/docs/providers/aws_sagemaker)## [🗃️ Bedrock3 items](/docs/providers/bedrock)## [📄️ LiteLLM Proxy (LLM Gateway)| Property | Details |](/docs/providers/litellm_proxy)## [📄️ Meta Llama| Property | Details |](/docs/providers/meta_llama)## [📄️ Mistral AI APIhttps://docs.mistral.ai/api/](/docs/providers/mistral)## [📄️ Codestral API [Mistral AI]Codestral is available in select code-completion plugins but can also be queried directly. See the documentation for more details.](/docs/providers/codestral)## [📄️ CohereAPI KEYS](/docs/providers/cohere)## [📄️ Anyscalehttps://app.endpoints.anyscale.com/](/docs/providers/anyscale)## [🗃️ HuggingFace2 items](/docs/providers/huggingface)## [📄️ DatabricksLiteLLM supports all models on Databricks](/docs/providers/databricks)## [📄️ DeepgramLiteLLM supports Deepgram's /listen endpoint.](/docs/providers/deepgram)## [📄️ IBM watsonx.aiLiteLLM supports all IBM watsonx.ai foundational models and embeddings.](/docs/providers/watsonx)## [📄️ PredibaseLiteLLM supports all models on Predibase](/docs/providers/predibase)## [📄️ Nvidia NIMhttps://docs.api.nvidia.com/nim/reference/](/docs/providers/nvidia_nim)## [📄️ Nscale (EU Sovereign)https://docs.nscale.com/docs/inference/chat](/docs/providers/nscale)## [📄️ xAIhttps://docs.x.ai/docs](/docs/providers/xai)## [📄️ LM Studiohttps://lmstudio.ai/docs/basics/server](/docs/providers/lm_studio)## [📄️ Cerebrashttps://inference-docs.cerebras.ai/api-reference/chat-completions](/docs/providers/cerebras)## [📄️ Volcano Engine (Volcengine)https://www.volcengine.com/docs/82379/1263482](/docs/providers/volcano)## [📄️ Triton Inference ServerLiteLLM supports Embedding Models on Triton Inference Servers](/docs/providers/triton-inference-server)## [📄️ OllamaLiteLLM supports all models from Ollama](/docs/providers/ollama)## [📄️ Perplexity AI (pplx-api)https://www.perplexity.ai](/docs/providers/perplexity)## [📄️ FriendliAIWe support ALL FriendliAI models, just set friendliai/ as a prefix when sending completion requests](/docs/providers/friendliai)## [📄️ Galadrielhttps://docs.galadriel.com/api-reference/chat-completion-API](/docs/providers/galadriel)## [📄️ Topaz| Property | Details |](/docs/providers/topaz)## [📄️ Groqhttps://groq.com/](/docs/providers/groq)## [📄️ 🆕 Githubhttps://github.com/marketplace/models](/docs/providers/github)## [📄️ Deepseekhttps://deepseek.com/](/docs/providers/deepseek)## [📄️ Fireworks AIWe support ALL Fireworks AI models, just set fireworks_ai/ as a prefix when sending completion requests](/docs/providers/fireworks_ai)## [📄️ ClarifaiAnthropic, OpenAI, Mistral, Llama and Gemini LLMs are Supported on Clarifai.](/docs/providers/clarifai)## [📄️ VLLMLiteLLM supports all models on VLLM.](/docs/providers/vllm)## [📄️ LlamafileLiteLLM supports all models on Llamafile.](/docs/providers/llamafile)## [📄️ Infinity| Property | Details |](/docs/providers/infinity)## [📄️ Xinference [Xorbits Inference]https://inference.readthedocs.io/en/latest/index.html](/docs/providers/xinference)## [📄️ Cloudflare Workers AIhttps://developers.cloudflare.com/workers-ai/models/text-generation/](/docs/providers/cloudflare_workers)## [📄️ DeepInfrahttps://deepinfra.com/](/docs/providers/deepinfra)## [📄️ AI21LiteLLM supports the following AI21 models:](/docs/providers/ai21)## [📄️ NLP CloudLiteLLM supports all LLMs on NLP Cloud.](/docs/providers/nlp_cloud)## [📄️ ReplicateLiteLLM supports all models on Replicate](/docs/providers/replicate)## [📄️ Together AILiteLLM supports all models on Together AI.](/docs/providers/togetherai)## [📄️ Novita AI| Property | Details |](/docs/providers/novita)## [📄️ Voyage AIhttps://docs.voyageai.com/embeddings/](/docs/providers/voyage)## [📄️ Jina AIhttps://jina.ai/embeddings/](/docs/providers/jina_ai)## [📄️ Aleph AlphaLiteLLM supports all models from Aleph Alpha.](/docs/providers/aleph_alpha)## [📄️ BasetenLiteLLM supports any Text-Gen-Interface models on Baseten.](/docs/providers/baseten)## [📄️ OpenRouterLiteLLM supports all the text / chat / vision models from OpenRouter](/docs/providers/openrouter)## [📄️ SambaNovahttps://cloud.sambanova.ai/](/docs/providers/sambanova)## [📄️ Custom API Server (Custom Format)Call your custom torch-serve / internal LLM APIs via LiteLLM](/docs/providers/custom_llm_server)## [📄️ PetalsPetals//github.com/bigscience-workshop/petals](/docs/providers/petals)## [📄️ Snowflake| Property | Details |](/docs/providers/snowflake)## [📄️ Featherless AIhttps://featherless.ai/](/docs/providers/featherless_ai)## [📄️ Nebius AI Studiohttps://docs.nebius.com/studio/inference/quickstart](/docs/providers/nebius)