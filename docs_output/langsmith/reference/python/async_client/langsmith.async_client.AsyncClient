# AsyncClient ‚Äî ü¶úÔ∏èüõ†Ô∏è LangSmith  documentation

# AsyncClient#

_class _langsmith.async_client.AsyncClient(

    _api_url : str | None = None_,
    _api_key : str | None = None_,
    _timeout_ms : int | tuple[int | None, int | None, int | None, int | None] | None = None_,
    _retry_config : Mapping[str, Any] | None = None_,
    _web_url : str | None = None_,
)[[source]](../_modules/langsmith/async_client.html#AsyncClient)#
    

Async Client for interacting with the LangSmith API.

Initialize the async client.

Methods

`__init__`([api_url, api_key, timeout_ms, ...]) | Initialize the async client.  
---|---  
`aclose`() | Close the async client.  
`add_runs_to_annotation_queue`(queue_id, *, ...) | Add runs to an annotation queue with the specified queue ID.  
`create_annotation_queue`(*, name[, ...]) | Create an annotation queue on the LangSmith API.  
`create_commit`(prompt_identifier, object, *) | Create a commit for an existing prompt.  
`create_dataset`(dataset_name, **kwargs) | Create a dataset.  
`create_example`(inputs[, outputs, ...]) | Create an example.  
`create_feedback`(run_id, key[, score, value, ...]) | Create feedback for a run.  
`create_feedback_from_token`(token_or_url[, ...]) | Create feedback from a presigned token or URL.  
`create_presigned_feedback_token`(run_id, ...) | Create a pre-signed URL to send feedback data to.  
`create_project`(project_name, **kwargs) | Create a project.  
`create_prompt`(prompt_identifier, *[, ...]) | Create a new prompt.  
`create_run`(name, inputs, run_type, *[, ...]) | Create a run.  
`delete_annotation_queue`(queue_id) | Delete an annotation queue with the specified queue ID.  
`delete_dataset`(dataset_id) | Delete a dataset.  
`delete_feedback`(feedback_id) | Delete a feedback by ID.  
`delete_project`(*[, project_name, project_id]) | Delete a project from LangSmith.  
`delete_prompt`(prompt_identifier) | Delete a prompt.  
`delete_run_from_annotation_queue`(queue_id, ...) | Delete a run from an annotation queue with the specified queue ID and run ID.  
`get_prompt`(prompt_identifier) | Get a specific prompt by its identifier.  
`get_run_from_annotation_queue`(queue_id, *, index) | Get a run from an annotation queue at the specified index.  
`index_dataset`(*, dataset_id[, tag]) | Enable dataset indexing.  
`like_prompt`(prompt_identifier) | Like a prompt.  
`list_annotation_queues`(*[, queue_ids, name, ...]) | List the annotation queues on the LangSmith API.  
`list_datasets`(**kwargs) | List datasets.  
`list_examples`(*[, dataset_id, dataset_name]) | List examples.  
`list_feedback`(*[, run_ids, feedback_key, ...]) | List feedback.  
`list_prompt_commits`(prompt_identifier, *[, ...]) | List commits for a given prompt.  
`list_prompts`(*[, limit, offset, is_public, ...]) | List prompts with pagination.  
`list_runs`(*[, project_id, project_name, ...]) | List runs from the LangSmith API.  
`pull_prompt`(prompt_identifier, *[, ...]) | Pull a prompt and return it as a LangChain PromptTemplate.  
`pull_prompt_commit`(prompt_identifier, *[, ...]) | Pull a prompt object from the LangSmith API.  
`push_prompt`(prompt_identifier, *[, object, ...]) | Push a prompt to the LangSmith API.  
`read_annotation_queue`(queue_id) | Read an annotation queue with the specified queue ID.  
`read_dataset`([dataset_name, dataset_id]) | Read a dataset.  
`read_example`(example_id) | Read an example.  
`read_feedback`(feedback_id) | Read feedback.  
`read_project`([project_name, project_id]) | Read a project.  
`read_run`(run_id) | Read a run.  
`read_run_shared_link`(run_id) | Retrieve the shared link for a specific run asynchronously.  
`run_is_shared`(run_id) | Get share state for a run asynchronously.  
`share_run`(run_id, *[, share_id]) | Get a share link for a run asynchronously.  
`similar_examples`(inputs, /, *, limit, dataset_id) | Retrieve the dataset examples whose inputs best match the current inputs.  
`sync_indexed_dataset`(*, dataset_id, **kwargs) | Sync dataset index.  
`unlike_prompt`(prompt_identifier) | Unlike a prompt.  
`update_annotation_queue`(queue_id, *, name[, ...]) | Update an annotation queue with the specified queue_id.  
`update_prompt`(prompt_identifier, *[, ...]) | Update a prompt's metadata.  
`update_run`(run_id, **kwargs) | Update a run.  
  
Parameters:
    

  * **api_url** (_Optional_ _[__str_ _]_)

  * **api_key** (_Optional_ _[__str_ _]_)

  * **timeout_ms** (_Optional_ _[__Union_ _[__int_ _,__tuple_ _[__Optional_ _[__int_ _]__,__Optional_ _[__int_ _]__,__Optional_ _[__int_ _]__,__Optional_ _[__int_ _]__]__]__]_)

  * **retry_config** (_Optional_ _[__Mapping_ _[__str_ _,__Any_ _]__]_)

  * **web_url** (_Optional_ _[__str_ _]_)

__init__(

    _api_url : str | None = None_,
    _api_key : str | None = None_,
    _timeout_ms : int | tuple[int | None, int | None, int | None, int | None] | None = None_,
    _retry_config : Mapping[str, Any] | None = None_,
    _web_url : str | None = None_,
)[[source]](../_modules/langsmith/async_client.html#AsyncClient.__init__)#
    

Initialize the async client.

Parameters:
    

  * **api_url** (_str_ _|__None_)

  * **api_key** (_str_ _|__None_)

  * **timeout_ms** (_int_ _|__tuple_ _[__int_ _|__None_ _,__int_ _|__None_ _,__int_ _|__None_ _,__int_ _|__None_ _]__|__None_)

  * **retry_config** (_Mapping_ _[__str_ _,__Any_ _]__|__None_)

  * **web_url** (_str_ _|__None_)

_async _aclose()[[source]](../_modules/langsmith/async_client.html#AsyncClient.aclose)#
    

Close the async client.

_async _add_runs_to_annotation_queue(

    _queue_id : UUID | str_,
    _*_ ,
    _run_ids : list[UUID | str]_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.add_runs_to_annotation_queue)#
    

Add runs to an annotation queue with the specified queue ID.

Parameters:
    

  * **queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue.

  * **run_ids** (_List_ _[__Union_ _[__UUID_ _,__str_ _]__]_) ‚Äì The IDs of the runs to be added to the annotation queue.

Returns:
    

None

Return type:
    

None

_async _create_annotation_queue(

    _*_ ,
    _name : str_,
    _description : str | None = None_,
    _queue_id : UUID | str | None = None_,
) ‚Üí [AnnotationQueue](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_annotation_queue)#
    

Create an annotation queue on the LangSmith API.

Parameters:
    

  * **name** (_str_) ‚Äì The name of the annotation queue.

  * **description** (_Optional_ _[__str_ _]_) ‚Äì The description of the annotation queue.

  * **queue_id** (_Optional_ _[__Union_ _[__UUID_ _,__str_ _]__]_) ‚Äì The ID of the annotation queue.

Returns:
    

The created annotation queue object.

Return type:
    

[AnnotationQueue](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")

_async _create_commit(

    _prompt_identifier : str_,
    _object : Any_,
    _*_ ,
    _parent_commit_hash : str | None = None_,
) ‚Üí str[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_commit)#
    

Create a commit for an existing prompt.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

  * **object** (_Any_) ‚Äì The LangChain object to commit.

  * **parent_commit_hash** (_Optional_ _[__str_ _]_) ‚Äì The hash of the parent commit. Defaults to latest commit.

Returns:
    

The url of the prompt commit.

Return type:
    

str

Raises:
    

  * **HTTPError** ‚Äì If the server request fails.

  * **ValueError** ‚Äì If the prompt does not exist.

_async _create_dataset(

    _dataset_name : str_,
    _** kwargs: Any_,
) ‚Üí [Dataset](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_dataset)#
    

Create a dataset.

Parameters:
    

  * **dataset_name** (_str_)

  * **kwargs** (_Any_)

Return type:
    

[_Dataset_](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")

_async _create_example(

    _inputs : dict[str, Any]_,
    _outputs : dict[str, Any] | None = None_,
    _dataset_id : UUID | str | None = None_,
    _dataset_name : str | None = None_,
    _** kwargs: Any_,
) ‚Üí [Example](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_example)#
    

Create an example.

Parameters:
    

  * **inputs** (_dict_ _[__str_ _,__Any_ _]_)

  * **outputs** (_dict_ _[__str_ _,__Any_ _]__|__None_)

  * **dataset_id** (_UUID_ _|__str_ _|__None_)

  * **dataset_name** (_str_ _|__None_)

  * **kwargs** (_Any_)

Return type:
    

[_Example_](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")

_async _create_feedback(

    _run_id : UUID | str | None_,
    _key : str_,
    _score : float | None = None_,
    _value : Any | None = None_,
    _comment : str | None = None_,
    _** kwargs: Any_,
) ‚Üí [Feedback](../schemas/langsmith.schemas.Feedback.html#langsmith.schemas.Feedback "langsmith.schemas.Feedback")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_feedback)#
    

Create feedback for a run.

Parameters:
    

  * **run_id** (_Optional_ _[__ls_client.ID_TYPE_ _]_) ‚Äì The ID of the run to provide feedback for. Can be None for project-level feedback.

  * **key** (_str_) ‚Äì The name of the metric or aspect this feedback is about.

  * **score** (_Optional_ _[__float_ _]_) ‚Äì The score to rate this run on the metric or aspect.

  * **value** (_Optional_ _[__Any_ _]_) ‚Äì The display value or non-numeric value for this feedback.

  * **comment** (_Optional_ _[__str_ _]_) ‚Äì A comment about this feedback.

  * ****kwargs** ‚Äì Additional keyword arguments to include in the feedback data.

Returns:
    

The created feedback object.

Return type:
    

ls_schemas.Feedback

Raises:
    

**httpx.HTTPStatusError** ‚Äì If the API request fails.

_async _create_feedback_from_token(

    _token_or_url : str | UUID_,
    _score : float | int | bool | None = None_,
    _*_ ,
    _value : float | int | bool | str | dict | None = None_,
    _correction : dict | None = None_,
    _comment : str | None = None_,
    _metadata : dict | None = None_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_feedback_from_token)#
    

Create feedback from a presigned token or URL.

Parameters:
    

  * **token_or_url** (_Union_ _[__str_ _,__uuid.UUID_ _]_) ‚Äì The token or URL from which to create feedback.

  * **score** (_Union_ _[__float_ _,__int_ _,__bool_ _,__None_ _]__,__optional_) ‚Äì The score of the feedback. Defaults to None.

  * **value** (_Union_ _[__float_ _,__int_ _,__bool_ _,__str_ _,__dict_ _,__None_ _]__,__optional_) ‚Äì The value of the feedback. Defaults to None.

  * **correction** (_Union_ _[__dict_ _,__None_ _]__,__optional_) ‚Äì The correction of the feedback. Defaults to None.

  * **comment** (_Union_ _[__str_ _,__None_ _]__,__optional_) ‚Äì The comment of the feedback. Defaults to None.

  * **metadata** (_Optional_ _[__dict_ _]__,__optional_) ‚Äì Additional metadata for the feedback. Defaults to None.

Raises:
    

**ValueError** ‚Äì If the source API URL is invalid.

Returns:
    

This method does not return anything.

Return type:
    

None

_async _create_presigned_feedback_token(

    _run_id : UUID | str_,
    _feedback_key : str_,
    _*_ ,
    _expiration : datetime | timedelta | None = None_,
    _feedback_config : [FeedbackConfig](../schemas/langsmith.schemas.FeedbackConfig.html#langsmith.schemas.FeedbackConfig "langsmith.schemas.FeedbackConfig") | None = None_,
    _feedback_id : UUID | str | None = None_,
) ‚Üí [FeedbackIngestToken](../schemas/langsmith.schemas.FeedbackIngestToken.html#langsmith.schemas.FeedbackIngestToken "langsmith.schemas.FeedbackIngestToken")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_presigned_feedback_token)#
    

Create a pre-signed URL to send feedback data to.

This is useful for giving browser-based clients a way to upload feedback data directly to LangSmith without accessing the API key.

Parameters:
    

  * **run_id** (_UUID_ _|__str_)

  * **feedback_key** (_str_)

  * **expiration** (_datetime_ _|__timedelta_ _|__None_) ‚Äì The expiration time of the pre-signed URL. Either a datetime or a timedelta offset from now. Default to 3 hours.

  * **feedback_config** ([_FeedbackConfig_](../schemas/langsmith.schemas.FeedbackConfig.html#langsmith.schemas.FeedbackConfig "langsmith.schemas.FeedbackConfig") _|__None_) ‚Äì FeedbackConfig or None. If creating a feedback_key for the first time, this defines how the metric should be interpreted, such as a continuous score (w/ optional bounds), or distribution over categorical values.

  * **feedback_id** (_UUID_ _|__str_ _|__None_) ‚Äì The ID of the feedback to create. If not provided, a new feedback will be created.

Returns:
    

The pre-signed URL for uploading feedback data.

Return type:
    

[_FeedbackIngestToken_](../schemas/langsmith.schemas.FeedbackIngestToken.html#langsmith.schemas.FeedbackIngestToken "langsmith.schemas.FeedbackIngestToken")

_async _create_project(

    _project_name : str_,
    _** kwargs: Any_,
) ‚Üí [TracerSession](../schemas/langsmith.schemas.TracerSession.html#langsmith.schemas.TracerSession "langsmith.schemas.TracerSession")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_project)#
    

Create a project.

Parameters:
    

  * **project_name** (_str_)

  * **kwargs** (_Any_)

Return type:
    

[_TracerSession_](../schemas/langsmith.schemas.TracerSession.html#langsmith.schemas.TracerSession "langsmith.schemas.TracerSession")

_async _create_prompt(

    _prompt_identifier : str_,
    _*_ ,
    _description : str | None = None_,
    _readme : str | None = None_,
    _tags : Sequence[str] | None = None_,
    _is_public : bool = False_,
) ‚Üí [Prompt](../schemas/langsmith.schemas.Prompt.html#langsmith.schemas.Prompt "langsmith.schemas.Prompt")[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_prompt)#
    

Create a new prompt.

Does not attach prompt object, just creates an empty prompt.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt. The identifier should be in the formatof owner/name:hash, name:hash, owner/name, or name

  * **description** (_Optional_ _[__str_ _]_) ‚Äì A description of the prompt.

  * **readme** (_Optional_ _[__str_ _]_) ‚Äì A readme for the prompt.

  * **tags** (_Optional_ _[__Sequence_ _[__str_ _]__]_) ‚Äì A list of tags for the prompt.

  * **is_public** (_bool_) ‚Äì Whether the prompt should be public. Defaults to False.

Returns:
    

The created prompt object.

Return type:
    

[Prompt](../schemas/langsmith.schemas.Prompt.html#langsmith.schemas.Prompt "langsmith.schemas.Prompt")

Raises:
    

  * **ValueError** ‚Äì If the current tenant is not the owner.

  * **HTTPError** ‚Äì If the server request fails.

_async _create_run(

    _name : str_,
    _inputs : dict[str, Any]_,
    _run_type : str_,
    _*_ ,
    _project_name : str | None = None_,
    _revision_id : UUID | str | None = None_,
    _** kwargs: Any_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.create_run)#
    

Create a run.

Parameters:
    

  * **name** (_str_)

  * **inputs** (_dict_ _[__str_ _,__Any_ _]_)

  * **run_type** (_str_)

  * **project_name** (_str_ _|__None_)

  * **revision_id** (_UUID_ _|__str_ _|__None_)

  * **kwargs** (_Any_)

Return type:
    

None

_async _delete_annotation_queue(

    _queue_id : UUID | str_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_annotation_queue)#
    

Delete an annotation queue with the specified queue ID.

Parameters:
    

**queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue to delete.

Returns:
    

None

Return type:
    

None

_async _delete_dataset(

    _dataset_id : UUID | str_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_dataset)#
    

Delete a dataset.

Parameters:
    

**dataset_id** (_UUID_ _|__str_)

Return type:
    

None

_async _delete_feedback(

    _feedback_id : UUID | str_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_feedback)#
    

Delete a feedback by ID.

Parameters:
    

**feedback_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the feedback to delete.

Returns:
    

None

Return type:
    

None

_async _delete_project(

    _*_ ,
    _project_name : str | None = None_,
    _project_id : str | None = None_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_project)#
    

Delete a project from LangSmith.

Parameters:
    

  * **project_name** (_str_ _or_ _None_ _,__default=None_) ‚Äì The name of the project to delete.

  * **project_id** (_str_ _or_ _None_ _,__default=None_) ‚Äì The ID of the project to delete.

Return type:
    

None

_async _delete_prompt(_prompt_identifier : str_) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_prompt)#
    

Delete a prompt.

Parameters:
    

**prompt_identifier** (_str_) ‚Äì The identifier of the prompt to delete.

Returns:
    

True if the prompt was successfully deleted, False otherwise.

Return type:
    

bool

Raises:
    

**ValueError** ‚Äì If the current tenant is not the owner of the prompt.

_async _delete_run_from_annotation_queue(

    _queue_id : UUID | str_,
    _*_ ,
    _run_id : UUID | str_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.delete_run_from_annotation_queue)#
    

Delete a run from an annotation queue with the specified queue ID and run ID.

Parameters:
    

  * **queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue.

  * **run_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the run to be added to the annotation queue.

Returns:
    

None

Return type:
    

None

_async _get_prompt(

    _prompt_identifier : str_,
) ‚Üí [Prompt](../schemas/langsmith.schemas.Prompt.html#langsmith.schemas.Prompt "langsmith.schemas.Prompt") | None[[source]](../_modules/langsmith/async_client.html#AsyncClient.get_prompt)#
    

Get a specific prompt by its identifier.

Parameters:
    

**prompt_identifier** (_str_) ‚Äì The identifier of the prompt. The identifier should be in the format ‚Äúprompt_name‚Äù or ‚Äúowner/prompt_name‚Äù.

Returns:
    

The prompt object.

Return type:
    

Optional[[Prompt](../schemas/langsmith.schemas.Prompt.html#langsmith.schemas.Prompt "langsmith.schemas.Prompt")]

Raises:
    

**requests.exceptions.HTTPError** ‚Äì If the prompt is not found or another error occurs.

_async _get_run_from_annotation_queue(

    _queue_id : UUID | str_,
    _*_ ,
    _index : int_,
) ‚Üí [RunWithAnnotationQueueInfo](../schemas/langsmith.schemas.RunWithAnnotationQueueInfo.html#langsmith.schemas.RunWithAnnotationQueueInfo "langsmith.schemas.RunWithAnnotationQueueInfo")[[source]](../_modules/langsmith/async_client.html#AsyncClient.get_run_from_annotation_queue)#
    

Get a run from an annotation queue at the specified index.

Parameters:
    

  * **queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue.

  * **index** (_int_) ‚Äì The index of the run to retrieve.

Returns:
    

The run at the specified index.

Return type:
    

[RunWithAnnotationQueueInfo](../schemas/langsmith.schemas.RunWithAnnotationQueueInfo.html#langsmith.schemas.RunWithAnnotationQueueInfo "langsmith.schemas.RunWithAnnotationQueueInfo")

Raises:
    

  * [**LangSmithNotFoundError**](../utils/langsmith.utils.LangSmithNotFoundError.html#langsmith.utils.LangSmithNotFoundError "langsmith.utils.LangSmithNotFoundError") ‚Äì If the run is not found at the given index.

  * [**LangSmithError**](../utils/langsmith.utils.LangSmithError.html#langsmith.utils.LangSmithError "langsmith.utils.LangSmithError") ‚Äì For other API-related errors.

index_dataset(

    _*_ ,
    _dataset_id : UUID | str_,
    _tag : str = 'latest'_,
    _** kwargs: Any_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.index_dataset)#
    

Enable dataset indexing. Examples are indexed by their inputs.

This enables searching for similar examples by inputs with `client.similar_examples()`.

Parameters:
    

  * **dataset_id** (_UUID_) ‚Äì The ID of the dataset to index.

  * **tag** (_str_ _,__optional_) ‚Äì The version of the dataset to index. If ‚Äòlatest‚Äô then any updates to the dataset (additions, updates, deletions of examples) will be reflected in the index.

  * **kwargs** (_Any_)

Returns:
    

None

Raises:
    

**requests.HTTPError** ‚Äì 

Return type:
    

None

_async _like_prompt(

    _prompt_identifier : str_,
) ‚Üí dict[str, int][[source]](../_modules/langsmith/async_client.html#AsyncClient.like_prompt)#
    

Like a prompt.

Parameters:
    

**prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

Returns:
    

A dictionary with the key ‚Äòlikes‚Äô and the count of likes as the value.

Return type:
    

Dict[str, int]

_async _list_annotation_queues(

    _*_ ,
    _queue_ids : list[UUID | str] | None = None_,
    _name : str | None = None_,
    _name_contains : str | None = None_,
    _limit : int | None = None_,
) ‚Üí AsyncIterator[[AnnotationQueue](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_annotation_queues)#
    

List the annotation queues on the LangSmith API.

Parameters:
    

  * **queue_ids** (_Optional_ _[__List_ _[__Union_ _[__UUID_ _,__str_ _]__]__]_) ‚Äì The IDs of the queues to filter by.

  * **name** (_Optional_ _[__str_ _]_) ‚Äì The name of the queue to filter by.

  * **name_contains** (_Optional_ _[__str_ _]_) ‚Äì The substring that the queue name should contain.

  * **limit** (_Optional_ _[__int_ _]_) ‚Äì The maximum number of queues to return.

Yields:
    

The annotation queues.

Return type:
    

_AsyncIterator_[[_AnnotationQueue_](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")]

_async _list_datasets(

    _** kwargs: Any_,
) ‚Üí AsyncIterator[[Dataset](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_datasets)#
    

List datasets.

Parameters:
    

**kwargs** (_Any_)

Return type:
    

_AsyncIterator_[[_Dataset_](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")]

_async _list_examples(

    _*_ ,
    _dataset_id : UUID | str | None = None_,
    _dataset_name : str | None = None_,
    _** kwargs: Any_,
) ‚Üí AsyncIterator[[Example](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_examples)#
    

List examples.

Parameters:
    

  * **dataset_id** (_UUID_ _|__str_ _|__None_)

  * **dataset_name** (_str_ _|__None_)

  * **kwargs** (_Any_)

Return type:
    

_AsyncIterator_[[_Example_](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")]

_async _list_feedback(

    _*_ ,
    _run_ids : Sequence[UUID | str] | None = None_,
    _feedback_key : Sequence[str] | None = None_,
    _feedback_source_type : Sequence[[FeedbackSourceType](../schemas/langsmith.schemas.FeedbackSourceType.html#langsmith.schemas.FeedbackSourceType "langsmith.schemas.FeedbackSourceType")] | None = None_,
    _limit : int | None = None_,
    _** kwargs: Any_,
) ‚Üí AsyncIterator[[Feedback](../schemas/langsmith.schemas.Feedback.html#langsmith.schemas.Feedback "langsmith.schemas.Feedback")][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_feedback)#
    

List feedback.

Parameters:
    

  * **run_ids** (_Sequence_ _[__UUID_ _|__str_ _]__|__None_)

  * **feedback_key** (_Sequence_ _[__str_ _]__|__None_)

  * **feedback_source_type** (_Sequence_ _[_[_FeedbackSourceType_](../schemas/langsmith.schemas.FeedbackSourceType.html#langsmith.schemas.FeedbackSourceType "langsmith.schemas.FeedbackSourceType") _]__|__None_)

  * **limit** (_int_ _|__None_)

  * **kwargs** (_Any_)

Return type:
    

_AsyncIterator_[[_Feedback_](../schemas/langsmith.schemas.Feedback.html#langsmith.schemas.Feedback "langsmith.schemas.Feedback")]

_async _list_prompt_commits(

    _prompt_identifier : str_,
    _*_ ,
    _limit : int | None = None_,
    _offset : int = 0_,
    _include_model : bool = False_,
) ‚Üí AsyncGenerator[[ListedPromptCommit](../schemas/langsmith.schemas.ListedPromptCommit.html#langsmith.schemas.ListedPromptCommit "langsmith.schemas.ListedPromptCommit"), None][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_prompt_commits)#
    

List commits for a given prompt.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt in the format ‚Äòowner/repo_name‚Äô.

  * **limit** (_Optional_ _[__int_ _]_) ‚Äì The maximum number of commits to return. If None, returns all commits. Defaults to None.

  * **offset** (_int_ _,__default=0_) ‚Äì The number of commits to skip before starting to return results. Defaults to 0.

  * **include_model** (_bool_ _,__default=False_) ‚Äì Whether to include the model information in the commit data. Defaults to False.

Yields:
    

A ListedPromptCommit object for each commit.

Return type:
    

_AsyncGenerator_[[_ListedPromptCommit_](../schemas/langsmith.schemas.ListedPromptCommit.html#langsmith.schemas.ListedPromptCommit "langsmith.schemas.ListedPromptCommit"), None]

Note

This method uses pagination to retrieve commits. It will make multiple API calls if necessary to retrieve all commits or up to the specified limit.

_async _list_prompts(

    _*_ ,
    _limit : int = 100_,
    _offset : int = 0_,
    _is_public : bool | None = None_,
    _is_archived : bool | None = False_,
    _sort_field : [PromptSortField](../schemas/langsmith.schemas.PromptSortField.html#langsmith.schemas.PromptSortField "langsmith.schemas.PromptSortField") = PromptSortField.updated_at_,
    _sort_direction : Literal['desc', 'asc'] = 'desc'_,
    _query : str | None = None_,
) ‚Üí [ListPromptsResponse](../schemas/langsmith.schemas.ListPromptsResponse.html#langsmith.schemas.ListPromptsResponse "langsmith.schemas.ListPromptsResponse")[[source]](../_modules/langsmith/async_client.html#AsyncClient.list_prompts)#
    

List prompts with pagination.

Parameters:
    

  * **limit** (_int_ _,__default=100_) ‚Äì The maximum number of prompts to return. Defaults to 100.

  * **offset** (_int_ _,__default=0_) ‚Äì The number of prompts to skip. Defaults to 0.

  * **is_public** (_Optional_ _[__bool_ _]_) ‚Äì Filter prompts by if they are public.

  * **is_archived** (_Optional_ _[__bool_ _]_) ‚Äì Filter prompts by if they are archived.

  * **sort_field** ([_PromptSortField_](../schemas/langsmith.schemas.PromptSortField.html#langsmith.schemas.PromptSortField "langsmith.schemas.PromptSortField")) ‚Äì The field to sort by. Defaults to ‚Äúupdated_at‚Äù.

  * **sort_direction** (_Literal_ _[__"desc"__,__"asc"__]__,__default="desc"_) ‚Äì The order to sort by. Defaults to ‚Äúdesc‚Äù.

  * **query** (_Optional_ _[__str_ _]_) ‚Äì Filter prompts by a search query.

Returns:
    

A response object containing the list of prompts.

Return type:
    

[ListPromptsResponse](../schemas/langsmith.schemas.ListPromptsResponse.html#langsmith.schemas.ListPromptsResponse "langsmith.schemas.ListPromptsResponse")

_async _list_runs(

    _*_ ,
    _project_id : UUID | str | Sequence[UUID | str] | None = None_,
    _project_name : str | Sequence[str] | None = None_,
    _run_type : str | None = None_,
    _trace_id : UUID | str | None = None_,
    _reference_example_id : UUID | str | None = None_,
    _query : str | None = None_,
    _filter : str | None = None_,
    _trace_filter : str | None = None_,
    _tree_filter : str | None = None_,
    _is_root : bool | None = None_,
    _parent_run_id : UUID | str | None = None_,
    _start_time : datetime | None = None_,
    _error : bool | None = None_,
    _run_ids : Sequence[UUID | str] | None = None_,
    _select : Sequence[str] | None = None_,
    _limit : int | None = None_,
    _** kwargs: Any_,
) ‚Üí AsyncIterator[[Run](../schemas/langsmith.schemas.Run.html#langsmith.schemas.Run "langsmith.schemas.Run")][[source]](../_modules/langsmith/async_client.html#AsyncClient.list_runs)#
    

List runs from the LangSmith API.

Parameters:
    

  * **project_id** (_UUID_ _or_ _None_ _,__default=None_) ‚Äì The ID(s) of the project to filter by.

  * **project_name** (_str_ _or_ _None_ _,__default=None_) ‚Äì The name(s) of the project to filter by.

  * **run_type** (_str_ _or_ _None_ _,__default=None_) ‚Äì The type of the runs to filter by.

  * **trace_id** (_UUID_ _or_ _None_ _,__default=None_) ‚Äì The ID of the trace to filter by.

  * **reference_example_id** (_UUID_ _or_ _None_ _,__default=None_) ‚Äì The ID of the reference example to filter by.

  * **query** (_str_ _or_ _None_ _,__default=None_) ‚Äì The query string to filter by.

  * **filter** (_str_ _or_ _None_ _,__default=None_) ‚Äì The filter string to filter by.

  * **trace_filter** (_str_ _or_ _None_ _,__default=None_) ‚Äì Filter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.

  * **tree_filter** (_str_ _or_ _None_ _,__default=None_) ‚Äì Filter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.

  * **is_root** (_bool_ _or_ _None_ _,__default=None_) ‚Äì Whether to filter by root runs.

  * **parent_run_id** (_UUID_ _or_ _None_ _,__default=None_) ‚Äì The ID of the parent run to filter by.

  * **start_time** (_datetime_ _or_ _None_ _,__default=None_) ‚Äì The start time to filter by.

  * **error** (_bool_ _or_ _None_ _,__default=None_) ‚Äì Whether to filter by error status.

  * **run_ids** (_List_ _[__str_ _or_ _UUID_ _] or_ _None_ _,__default=None_) ‚Äì The IDs of the runs to filter by.

  * **limit** (_int_ _or_ _None_ _,__default=None_) ‚Äì The maximum number of runs to return.

  * ****kwargs** (_Any_) ‚Äì Additional keyword arguments.

  * **Yields**

  * **\------**

  * **Run** ‚Äì The runs.

  * **Examples**

  * **\--------**

  * **project** (_List root traces in a_)

  * **code-block:** (_.._) ‚Äì python: project_runs = client.list_runs(project_name=‚Äù<your_project>‚Äù)

  * **hours** (_List LLM and Chat runs in the last 24_)

  * **code-block:** ‚Äì 

python: todays_llm_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, start_time=datetime.now() - timedelta(days=1), run_type=‚Äùllm‚Äù,

)

  * **project**

  * **code-block:** ‚Äì python: root_runs = client.list_runs(project_name=‚Äù<your_project>‚Äù, is_root=1)

  * **errors** (_List runs without_)

  * **code-block:** ‚Äì python: correct_runs = client.list_runs(project_name=‚Äù<your_project>‚Äù, error=False)

  * **query****)** (_List runs and only return their inputs/outputs_ _(__to speed up the_)

  * **code-block:** ‚Äì 

python: input_output_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, select=[‚Äúinputs‚Äù, ‚Äúoutputs‚Äù]

)

  * **ID** (_List runs by run_)

  * **code-block:** ‚Äì 

python: run_ids = [

> ‚Äùa36092d2-4ad5-4fb4-9c0d-0dba9a2ed836‚Äù, ‚Äú9398e6be-964f-4aa4-8ae9-ad78cd4b7074‚Äù,

] selected_runs = client.list_runs(id=run_ids)

  * **had** (_List all "chain" type runs that took more than 10 seconds and_)

  * **5000** (_total_tokens greater than_)

  * **code-block:** ‚Äì 

python: chain_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, filter=‚Äôand(eq(run_type, ‚Äúchain‚Äù), gt(latency, 10), gt(total_tokens, 5000))‚Äô,

)

  * **1** (_List all runs called "extractor" whose root_ _of_ _the trace was assigned feedback "user_score" score of_)

  * **code-block:** ‚Äì 

python: good_extractor_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, filter=‚Äôeq(name, ‚Äúextractor‚Äù)‚Äô, trace_filter=‚Äôand(eq(feedback_key, ‚Äúuser_score‚Äù), eq(feedback_score, 1))‚Äô,

)

  * **0** (_List all runs that started after a specific timestamp and either have "error" not equal to null_ _or_ _a "Correctness" feedback score equal to_)

  * **code-block:** ‚Äì 

python: complex_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, filter=‚Äôand(gt(start_time, ‚Äú2023-07-15T12:34:56Z‚Äù), or(neq(error, null), and(eq(feedback_key, ‚ÄúCorrectness‚Äù), eq(feedback_score, 0.0))))‚Äô,

)

  * **seconds** (_List all runs where tags include "experimental"__or_ _"beta" and latency is greater than 2_)

  * **code-block:** ‚Äì 

python: tagged_runs = client.list_runs(

> project_name=‚Äù<your_project>‚Äù, filter=‚Äôand(or(has(tags, ‚Äúexperimental‚Äù), has(tags, ‚Äúbeta‚Äù)), gt(latency, 2))‚Äô,

)

  * **select** (_Sequence_ _[__str_ _]__|__None_)

Return type:
    

_AsyncIterator_[[_Run_](../schemas/langsmith.schemas.Run.html#langsmith.schemas.Run "langsmith.schemas.Run")]

_async _pull_prompt(

    _prompt_identifier : str_,
    _*_ ,
    _include_model : bool | None = False_,
) ‚Üí Any[[source]](../_modules/langsmith/async_client.html#AsyncClient.pull_prompt)#
    

Pull a prompt and return it as a LangChain PromptTemplate.

This method requires langchain_core.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

  * **include_model** (_Optional_ _[__bool_ _]__,__default=False_) ‚Äì Whether to include the model information in the prompt data.

Returns:
    

The prompt object in the specified format.

Return type:
    

Any

_async _pull_prompt_commit(

    _prompt_identifier : str_,
    _*_ ,
    _include_model : bool | None = False_,
) ‚Üí [PromptCommit](../schemas/langsmith.schemas.PromptCommit.html#langsmith.schemas.PromptCommit "langsmith.schemas.PromptCommit")[[source]](../_modules/langsmith/async_client.html#AsyncClient.pull_prompt_commit)#
    

Pull a prompt object from the LangSmith API.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

  * **include_model** (_bool_ _|__None_)

Returns:
    

The prompt object.

Return type:
    

[PromptCommit](../schemas/langsmith.schemas.PromptCommit.html#langsmith.schemas.PromptCommit "langsmith.schemas.PromptCommit")

Raises:
    

**ValueError** ‚Äì If no commits are found for the prompt.

_async _push_prompt(

    _prompt_identifier : str_,
    _*_ ,
    _object : Any | None = None_,
    _parent_commit_hash : str = 'latest'_,
    _is_public : bool | None = None_,
    _description : str | None = None_,
    _readme : str | None = None_,
    _tags : Sequence[str] | None = None_,
) ‚Üí str[[source]](../_modules/langsmith/async_client.html#AsyncClient.push_prompt)#
    

Push a prompt to the LangSmith API.

Can be used to update prompt metadata or prompt content.

If the prompt does not exist, it will be created. If the prompt exists, it will be updated.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

  * **object** (_Optional_ _[__Any_ _]_) ‚Äì The LangChain object to push.

  * **parent_commit_hash** (_str_) ‚Äì The parent commit hash. Defaults to ‚Äúlatest‚Äù.

  * **is_public** (_Optional_ _[__bool_ _]_) ‚Äì Whether the prompt should be public. If None (default), the current visibility status is maintained for existing prompts. For new prompts, None defaults to private. Set to True to make public, or False to make private.

  * **description** (_Optional_ _[__str_ _]_) ‚Äì A description of the prompt. Defaults to an empty string.

  * **readme** (_Optional_ _[__str_ _]_) ‚Äì A readme for the prompt. Defaults to an empty string.

  * **tags** (_Optional_ _[__Sequence_ _[__str_ _]__]_) ‚Äì A list of tags for the prompt. Defaults to an empty list.

Returns:
    

The URL of the prompt.

Return type:
    

str

_async _read_annotation_queue(

    _queue_id : UUID | str_,
) ‚Üí [AnnotationQueue](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_annotation_queue)#
    

Read an annotation queue with the specified queue ID.

Parameters:
    

**queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue to read.

Returns:
    

The annotation queue object.

Return type:
    

[AnnotationQueue](../schemas/langsmith.schemas.AnnotationQueue.html#langsmith.schemas.AnnotationQueue "langsmith.schemas.AnnotationQueue")

_async _read_dataset(

    _dataset_name : str | None = None_,
    _dataset_id : UUID | str | None = None_,
) ‚Üí [Dataset](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_dataset)#
    

Read a dataset.

Parameters:
    

  * **dataset_name** (_str_ _|__None_)

  * **dataset_id** (_UUID_ _|__str_ _|__None_)

Return type:
    

[_Dataset_](../schemas/langsmith.schemas.Dataset.html#langsmith.schemas.Dataset "langsmith.schemas.Dataset")

_async _read_example(

    _example_id : UUID | str_,
) ‚Üí [Example](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_example)#
    

Read an example.

Parameters:
    

**example_id** (_UUID_ _|__str_)

Return type:
    

[_Example_](../schemas/langsmith.schemas.Example.html#langsmith.schemas.Example "langsmith.schemas.Example")

_async _read_feedback(

    _feedback_id : UUID | str_,
) ‚Üí [Feedback](../schemas/langsmith.schemas.Feedback.html#langsmith.schemas.Feedback "langsmith.schemas.Feedback")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_feedback)#
    

Read feedback.

Parameters:
    

**feedback_id** (_UUID_ _|__str_)

Return type:
    

[_Feedback_](../schemas/langsmith.schemas.Feedback.html#langsmith.schemas.Feedback "langsmith.schemas.Feedback")

_async _read_project(

    _project_name : str | None = None_,
    _project_id : UUID | str | None = None_,
) ‚Üí [TracerSession](../schemas/langsmith.schemas.TracerSession.html#langsmith.schemas.TracerSession "langsmith.schemas.TracerSession")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_project)#
    

Read a project.

Parameters:
    

  * **project_name** (_str_ _|__None_)

  * **project_id** (_UUID_ _|__str_ _|__None_)

Return type:
    

[_TracerSession_](../schemas/langsmith.schemas.TracerSession.html#langsmith.schemas.TracerSession "langsmith.schemas.TracerSession")

_async _read_run(

    _run_id : UUID | str_,
) ‚Üí [Run](../schemas/langsmith.schemas.Run.html#langsmith.schemas.Run "langsmith.schemas.Run")[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_run)#
    

Read a run.

Parameters:
    

**run_id** (_UUID_ _|__str_)

Return type:
    

[_Run_](../schemas/langsmith.schemas.Run.html#langsmith.schemas.Run "langsmith.schemas.Run")

_async _read_run_shared_link(

    _run_id : UUID | str_,
) ‚Üí str | None[[source]](../_modules/langsmith/async_client.html#AsyncClient.read_run_shared_link)#
    

Retrieve the shared link for a specific run asynchronously.

Parameters:
    

**run_id** (_ID_TYPE_) ‚Äì The ID of the run.

Returns:
    

The shared link for the run, or None if the link is not available.

Return type:
    

Optional[str]

Raises:
    

**httpx.HTTPStatusError** ‚Äì If the API request fails.

_async _run_is_shared(_run_id : UUID | str_) ‚Üí bool[[source]](../_modules/langsmith/async_client.html#AsyncClient.run_is_shared)#
    

Get share state for a run asynchronously.

Parameters:
    

**run_id** (_UUID_ _|__str_)

Return type:
    

bool

_async _share_run(

    _run_id : UUID | str_,
    _*_ ,
    _share_id : UUID | str | None = None_,
) ‚Üí str[[source]](../_modules/langsmith/async_client.html#AsyncClient.share_run)#
    

Get a share link for a run asynchronously.

Parameters:
    

  * **run_id** (_ID_TYPE_) ‚Äì The ID of the run to share.

  * **share_id** (_Optional_ _[__ID_TYPE_ _]__,__optional_) ‚Äì Custom share ID. If not provided, a random UUID will be generated.

Returns:
    

The URL of the shared run.

Return type:
    

str

Raises:
    

**httpx.HTTPStatusError** ‚Äì If the API request fails.

similar_examples(

    _inputs : dict_,
    _/_ ,
    _*_ ,
    _limit : int_,
    _dataset_id : UUID | str_,
    _filter : str | None = None_,
    _** kwargs: Any_,
) ‚Üí list[[ExampleSearch](../schemas/langsmith.schemas.ExampleSearch.html#langsmith.schemas.ExampleSearch "langsmith.schemas.ExampleSearch")][[source]](../_modules/langsmith/async_client.html#AsyncClient.similar_examples)#
    

Retrieve the dataset examples whose inputs best match the current inputs.

**Note** : Must have few-shot indexing enabled for the dataset. See `client.index_dataset()`.

Parameters:
    

  * **inputs** (_dict_) ‚Äì The inputs to use as a search query. Must match the dataset input schema. Must be JSON serializable.

  * **limit** (_int_) ‚Äì The maximum number of examples to return.

  * **dataset_id** (_str_ _or_ _UUID_) ‚Äì The ID of the dataset to search over.

  * **filter** (_str_ _,__optional_) ‚Äì A filter string to apply to the search results. Uses the same syntax as the filter parameter in list_runs(). Only a subset of operations are supported. Defaults to None.

  * **kwargs** (_Any_) ‚Äì Additional keyword args to pass as part of request body.

Returns:
    

List of ExampleSearch objects.

Return type:
    

list[[_ExampleSearch_](../schemas/langsmith.schemas.ExampleSearch.html#langsmith.schemas.ExampleSearch "langsmith.schemas.ExampleSearch")]

Example
    
    
    from langsmith import Client
    
    client = Client()
    await client.similar_examples(
        {"question": "When would i use the runnable generator"},
        limit=3,
        dataset_id="...",
    )
    
    
    
    [
        ExampleSearch(
            inputs={'question': 'How do I cache a Chat model? What caches can I use?'},
            outputs={'answer': 'You can use LangChain\'s caching layer for Chat Models. This can save you money by reducing the number of API calls you make to the LLM provider, if you\'re often requesting the same completion multiple times, and speed up your application.\n\n```python\n\nfrom langchain.cache import InMemoryCache\nlangchain.llm_cache = InMemoryCache()\n\n# The first time, it is not yet in cache, so it should take longer\nllm.predict(\'Tell me a joke\')\n\n```\n\nYou can also use SQLite Cache which uses a SQLite database:\n\n```python\n  rm .langchain.db\n\nfrom langchain.cache import SQLiteCache\nlangchain.llm_cache = SQLiteCache(database_path=".langchain.db")\n\n# The first time, it is not yet in cache, so it should take longer\nllm.predict(\'Tell me a joke\') \n```\n'},
            metadata=None,
            id=UUID('b2ddd1c4-dff6-49ae-8544-f48e39053398'),
            dataset_id=UUID('01b6ce0f-bfb6-4f48-bbb8-f19272135d40')
        ),
        ExampleSearch(
            inputs={'question': "What's a runnable lambda?"},
            outputs={'answer': "A runnable lambda is an object that implements LangChain's `Runnable` interface and runs a callbale (i.e., a function). Note the function must accept a single argument."},
            metadata=None,
            id=UUID('f94104a7-2434-4ba7-8293-6a283f4860b4'),
            dataset_id=UUID('01b6ce0f-bfb6-4f48-bbb8-f19272135d40')
        ),
        ExampleSearch(
            inputs={'question': 'Show me how to use RecursiveURLLoader'},
            outputs={'answer': 'The RecursiveURLLoader comes from the langchain.document_loaders.recursive_url_loader module. Here\'s an example of how to use it:\n\n```python\nfrom langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader\n\n# Create an instance of RecursiveUrlLoader with the URL you want to load\nloader = RecursiveUrlLoader(url="https://example.com")\n\n# Load all child links from the URL page\nchild_links = loader.load()\n\n# Print the child links\nfor link in child_links:\n    print(link)\n```\n\nMake sure to replace "https://example.com" with the actual URL you want to load. The load() method returns a list of child links found on the URL page. You can iterate over this list to access each child link.'},
            metadata=None,
            id=UUID('0308ea70-a803-4181-a37d-39e95f138f8c'),
            dataset_id=UUID('01b6ce0f-bfb6-4f48-bbb8-f19272135d40')
        ),
    ]
    

sync_indexed_dataset(

    _*_ ,
    _dataset_id : UUID | str_,
    _** kwargs: Any_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.sync_indexed_dataset)#
    

Sync dataset index. This already happens automatically every 5 minutes, but you can call this to force a sync.

Parameters:
    

  * **dataset_id** (_UUID_) ‚Äì The ID of the dataset to sync.

  * **kwargs** (_Any_)

Returns:
    

None

Raises:
    

**requests.HTTPError** ‚Äì 

Return type:
    

None

_async _unlike_prompt(

    _prompt_identifier : str_,
) ‚Üí dict[str, int][[source]](../_modules/langsmith/async_client.html#AsyncClient.unlike_prompt)#
    

Unlike a prompt.

Parameters:
    

**prompt_identifier** (_str_) ‚Äì The identifier of the prompt.

Returns:
    

A dictionary with the key ‚Äòlikes‚Äô and the count of likes as the value.

Return type:
    

Dict[str, int]

_async _update_annotation_queue(

    _queue_id : UUID | str_,
    _*_ ,
    _name : str_,
    _description : str | None = None_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.update_annotation_queue)#
    

Update an annotation queue with the specified queue_id.

Parameters:
    

  * **queue_id** (_Union_ _[__UUID_ _,__str_ _]_) ‚Äì The ID of the annotation queue to update.

  * **name** (_str_) ‚Äì The new name for the annotation queue.

  * **description** (_Optional_ _[__str_ _]_) ‚Äì The new description for the annotation queue. Defaults to None.

Returns:
    

None

Return type:
    

None

_async _update_prompt(

    _prompt_identifier : str_,
    _*_ ,
    _description : str | None = None_,
    _readme : str | None = None_,
    _tags : Sequence[str] | None = None_,
    _is_public : bool | None = None_,
    _is_archived : bool | None = None_,
) ‚Üí dict[str, Any][[source]](../_modules/langsmith/async_client.html#AsyncClient.update_prompt)#
    

Update a prompt‚Äôs metadata.

To update the content of a prompt, use push_prompt or create_commit instead.

Parameters:
    

  * **prompt_identifier** (_str_) ‚Äì The identifier of the prompt to update.

  * **description** (_Optional_ _[__str_ _]_) ‚Äì New description for the prompt.

  * **readme** (_Optional_ _[__str_ _]_) ‚Äì New readme for the prompt.

  * **tags** (_Optional_ _[__Sequence_ _[__str_ _]__]_) ‚Äì New list of tags for the prompt.

  * **is_public** (_Optional_ _[__bool_ _]_) ‚Äì New public status for the prompt.

  * **is_archived** (_Optional_ _[__bool_ _]_) ‚Äì New archived status for the prompt.

Returns:
    

The updated prompt data as returned by the server.

Return type:
    

Dict[str, Any]

Raises:
    

  * **ValueError** ‚Äì If the prompt_identifier is empty.

  * **HTTPError** ‚Äì If the server request fails.

_async _update_run(

    _run_id : UUID | str_,
    _** kwargs: Any_,
) ‚Üí None[[source]](../_modules/langsmith/async_client.html#AsyncClient.update_run)#
    

Update a run.

Parameters:
    

  * **run_id** (_UUID_ _|__str_)

  * **kwargs** (_Any_)

Return type:
    

None

__On this page
  *[/]: Positional-only parameter separator (PEP 570)
  *[*]: Keyword-only parameters separator (PEP 3102)